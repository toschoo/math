%% =======================================================
%% (c) Tobias Schoofs
%% =======================================================
%% Math 4 Programmers - The Inverse Element
%% =======================================================

% Plain Style
\documentclass[tikz]{scrreprt}

% Springer Style
%\documentclass[envcountsame]{llncs}

%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%

\include{cmds}

\begin{document}
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}

\chapter{Real Numbers} % c06
\section{$\sqrt{2}$}
\ignore{
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{Sqrt2}{}\<[E]%
\\
\>[B]{}\mathbf{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Natural}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Quoz}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
}

Until now, we have looked at \term{discrete} numbers,
that is numbers that are nicely separated from each other
so that we can write them down unmistakebly
and always know of which number we are currently talking.
Now we enter a completely different universe.
The universe of continuous numbers that cannot be
written down in a finite number of steps.
The representation of these numbers consists of
infinitely many elements and, therefore, we will never
be able to write the number down completely
with all its elements.
We may give a finite formula 
that describes how to compute the specific number,
but we will never see the whole number written down.
Those numbers are known since antiquity and,
apparently, their existence came as a great surprise
to Greek mathematicians.

The first step of our investigations into
this kind of numbers, is to show that they \term{exist},
\ie, there are contexts where they arise naturally.
To start, we will assume that they are not necessary.
We assume that all numbers are either natural,
integral or fractional.
Indeed, any of the fundamental arithmetic operations,
$+,-,\times$ and $/$, applied on two rational numbers
results always in a rational number,
\ie\ an integer or a fraction.
We could therefore suspect
that the result of any operation is a rational number,
\ie\ an integer or a fraction.

What about $\sqrt{2}$, the square root of 2?
Let us assume that $\sqrt{2}$ is as well a fraction.
Then we have two integers $n$ and $d$,
coprime to each other, such that

\begin{equation}
\sqrt{2} = \frac{n}{d}
\end{equation}

and

\begin{equation}
2 = \left(\frac{n}{d}\right)^2 = \frac{n^2}{d^2}.
\end{equation}

Any number can be represented as a product of primes.
If $p_1p_2\dots p_n$ is the prime factorsiation of $n$
and $q_1q_2\dots q_d$ is that of $d$,
we can write:

\begin{equation}
\sqrt{2} = \frac{p_1p_2\dots p_n}{q_1q_2\dots q_d}.
\end{equation}

It follows that 

\begin{equation}\label{eq:sqrt2_4}
2 = \frac{p_1^2p_2^2\dots p_n^2}{q_1^2q_2^2\dots q_d^2}.
\end{equation}

As we know from the previous chapter,
two different prime numbers $p$ and $q$ squared 
(or raised to any integer)
do not result in two numbers that share factors.
The factorisation of $p^n$ is just $p^n$ and that
of $q^n$ is just $q^n$. They are coprime to each other.
The fraction in equation \ref{eq:sqrt2_4}, thus,
cannot represent an integer, such as 2.
There is only one way for such a fraction to
result in an integer, \viz, 
when the numerator is an integer and the denominator is 1,
which is obviously not the case for $\sqrt{2}$.
It follows that, if the root of an integer is not an integer itself,
it is not a rational number either.

But, if $\sqrt{2}$ is not a rational number,
a number that can be represented as the fraction
of two integers, what the heck is it then?

There are several methods to approximate the number $\sqrt{n}$.
The simplest and oldest is the \term{Babylonian} method,
also called \term{Heron's} method for Heron of Alexandria,
a Greek mathematician of the first century who lived in 
Alexandria.

The idea of Heron's method, basically, is to
iteratively approximate the real value starting with a guess.
We can start with some arbitrary value --
a good starting point, however, 
comes out of the root algorithm defined in the first chapter.
If $\sqrt{n}$ is not an integer, then our start value
is either slightly too big or too small,
\ie\ we either have $xx > n$ or $xx < n$.
So, on each step, we improve a bit on the value
by taking the average of $x$ and its counterpart $n/x$.
If $xx > n$, then clearly $n/x < x$ and, 
if $xx < n$, then $n/x > x$.
The average of $x$ and $a/x$ is calculated as
$(x+a/x)/2$. The result is used as guess for the next round.
The more iterations of this kind we do,
the better is the approximation. In Haskell:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{23}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{heron}\mathbin{::}\Conid{Natural}\to \Conid{Natural}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{heron}\;\Varid{n}\;\Varid{s}\mathrel{=}\mathbf{let}\;\Varid{a}{}\<[23]%
\>[23]{}\mathrel{=}\Varid{fromIntegral}\;\Varid{n}\;\mathbf{in}\;\Varid{go}\;\Varid{s}\;\Varid{a}\;(\Varid{a}\mathbin{/}\mathrm{2}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{go}\;\mathrm{0}\;\anonymous \;\Varid{x}{}\<[23]%
\>[23]{}\mathrel{=}\Varid{x}{}\<[E]%
\\
\>[12]{}\Varid{go}\;\Varid{i}\;\Varid{a}\;\Varid{x}{}\<[23]%
\>[23]{}\mathrel{=}\Varid{go}\;(\Varid{i}\mathbin{-}\mathrm{1})\;\Varid{a}\;((\Varid{x}\mathbin{+}\Varid{a}\mathbin{/}\Varid{x})\mathbin{/}\mathrm{2}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

The function takes two arguments.
The first is the number whose square root we want to calculate
and the second is the number of iterations.
We then call \ensuremath{\Varid{go}} with $s$, the number of iterations,
$a$, the \ensuremath{\Conid{Double}} representation of $n$, and our first guess
$a/2$.

In \ensuremath{\Varid{go}}, if we have reached $i=0$, we yield the result $x$.
Otherwise, we call \ensuremath{\Varid{go}} again with $i-1$, $a$ and 
the average of $x$ and $a/x$.

Let us compute $\sqrt{2}$ following this approach for, say,
five iterations. We first have

\begin{minipage}{\textwidth}
\ensuremath{\Varid{go}\;\mathrm{5}\;\mathrm{2}\;\mathrm{1}\mathrel{=}\Varid{go}\;\mathrm{4}\;\mathrm{2}\;((\mathrm{1}\mathbin{+}\mathrm{2})\mathbin{/}\mathrm{2})}\\
\ensuremath{\Varid{go}\;\mathrm{4}\;\mathrm{2}\;\mathrm{1.5}\mathrel{=}\Varid{go}\;\mathrm{3}\;\mathrm{2}\;((\mathrm{1.5}\mathbin{+}\mathrm{2}\mathbin{/}\mathrm{1.5})\mathbin{/}\mathrm{2})}\\
\ensuremath{\Varid{go}\;\mathrm{3}\;\mathrm{2}\;\mathrm{1.416666}\mathrel{=}\Varid{go}\;\mathrm{2}\;\mathrm{2}\;((\mathrm{1.416666}\mathbin{+}\mathrm{2}\mathbin{/}\mathrm{1.416666})\mathbin{/}\mathrm{2})}\\
\ensuremath{\Varid{go}\;\mathrm{2}\;\mathrm{2}\;\mathrm{1.414215}\mathrel{=}\Varid{go}\;\mathrm{1}\;\mathrm{2}\;((\mathrm{1.414215}\mathbin{+}\mathrm{2}\mathbin{/}\mathrm{1.414215})\mathbin{/}\mathrm{2})}\\
\ensuremath{\Varid{go}\;\mathrm{1}\;\mathrm{2}\;\mathrm{1.414213}\mathrel{=}\Varid{go}\;\mathrm{0}\;\mathrm{2}\;((\mathrm{1.414213}\mathbin{+}\mathrm{2}\mathbin{/}\mathrm{1.414213})\mathbin{/}\mathrm{2})}\\
\ensuremath{\Varid{go}\;\mathrm{1}\;\mathrm{2}\;\mathrm{1.414213}\mathrel{=}\mathrm{1.414213}}.
\end{minipage}

Note that we do not show the complete \ensuremath{\Conid{Double}} value,
but only the first six digits. The results of the last two
steps, therefore, are identical. They differ, in fact, at the
twelfth digit: 
$1.4142135623746899$ (\ensuremath{\Varid{heron}\;\mathrm{2}\;\mathrm{4}}) versus
$1.414213562373095$  (\ensuremath{\Varid{heron}\;\mathrm{2}\;\mathrm{5}}). 
Note that the result of five iterations has one digit less
than that of four iterations.
This is because that after the last digit, 5,
the digit 0 follows and then the \term{precision} of 
the Double number type is exhausted.
\term{Irrational} numbers, this is the designation of
the type of numbers we are talking about, 
consist of infinitely many digits. 
Therefore, the last digit in the number presented above
is in fact not the last digit of the number. 
With slightly higher precision, we would see that the number
continues like $03\dots$

The result of \ensuremath{(\Varid{heron}\;\mathrm{2}\;\mathrm{5})\mathbin{\uparrow}\mathrm{2}} is fairly close to 2: 
$1.9999999999999996$.
It will not get any closer using \ensuremath{\Conid{Double}} representation.
\section{$\Phi$}
\ignore{
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{Phi}{}\<[E]%
\\
\>[B]{}\mathbf{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Natural}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Quoz}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
}

Another interesting irrational number
is $\tau$ or $\Phi$,
known as the \term{divine proportion} or \term{golden ratio}.
The golden ratio is the relation of two quantities,
such that the greater relates to the lesser
as the sum of both to the greater.
This may sound confusing, so here are two symbolic
representations:

\begin{equation}
\frac{a}{b} = \frac{a+b}{a}.
\end{equation}

In this equation, $a$ is the greater number
and $b$ the lesser. The equation states
that the relation of $a$ to $b$ equals the relation
of $a+b$ to $a$.
Alternatively we can say

\begin{equation}\label{eq:phi_2}
\frac{b}{a} = \frac{a}{b-a}.
\end{equation}

Here $b$ is the sum of the two quantities
and $a$ is the greater one.
The equation states that the relation
of $b$ to $a$ is the same as the relation
of $a$ to $b-a$, which, of course, is
then the smaller quantity.

The golden ratio is known since antiquity.
The symbol $\Phi$ is an homage to ancient Greek
sculptor and painter Phidias (480 -- 430 \acronym{bc}).
Its first heyday after antiquity was
during Renaissance and then it was again
extremely popular in the $18^{th}$ and $19^{th}$ centuries.
Up to our times, artists, writers and mathematicians 
have repeatedly called the golden ratio 
especially pleasing. 

From equation \ref{eq:phi_2} we can derive
the numerical value of $\Phi$ in the form
$\frac{\Phi}{1}$.
We can then calculate $b$,
for any value $a$,
as $a\Phi$.
The derivation uses some algebraic methods,
which we will study more closely in the next part,
especially \term{completing the square}.
As such this section is also an algebra teaser.

We start by setting $\Phi = \frac{b}{a}$
with $a = 1$.
We then have on the left side of the equation
$\Phi = \frac{b}{1} = b$.
On the right-hand side, we have
$\frac{a=1}{\Phi - 1}$:

\begin{equation}
\Phi = \frac{1}{\Phi - 1}.
\end{equation}

Multiplying both sides by $\Phi - 1$,
we get 

\begin{equation}
\Phi^2 - \Phi = 1.
\end{equation}

This is a quadratic equation and,
with some phantasy, we even
recognise the fragment of a binomial formula on the
left side. A complete binomial formula would be

\begin{equation}
(a-b)^2 = a^2-2ab+b^2.
\end{equation}

We try to pattern match the fragment above
such that $\Phi^2$ is $a^2$ and $-\Phi$
is $-2ab$. That would mean that the last term,
$b^2$ would correspond to the square half of the number
that is multiplied by $\Phi$ to yield $-\Phi$.
$-\Phi$ can be seen as $-1 \times \Phi$.
Half of that number is $-\frac{1}{2}$.
That squared is $\frac{1}{4}$.
So, if we add $\frac{1}{4}$ to both sides of the equation,
we would end up with a complete binomial formula on 
the left side:

\begin{equation}
\Phi^2 - \Phi + \frac{1}{4} = 1 + \frac{1}{4} = \frac{5}{4}.
\end{equation}

We can apply the binomial theorem on the left side and get

\begin{equation}
\left(\Phi - \frac{1}{2}\right)^2 = \frac{5}{4}.
\end{equation}

Now we take the square root:

\begin{equation}
\Phi - \frac{1}{2} = \frac{\pm\sqrt{5}}{2}.
\end{equation}

Note that the $\pm$ in front of $\sqrt{5}$
reflects the fact that the square root
of 5 (or any other number) may be positive
or negative. Both solutions are possible.
However, since we are looking for a positive
relation, we only consider the positive solution
and ignore the other one. We can therefore simplify to

\begin{equation}
\Phi - \frac{1}{2} = \frac{\sqrt{5}}{2}.
\end{equation}

Finally, we add $\frac{1}{2}$ to both sides:

\begin{equation}
\Phi = \frac{1+\sqrt{5}}{2}
\end{equation}

and voilá that is $\Phi$.
The numerical value is approximately
\num{1.618033988749895}.
We can define it as a constant in Haskell as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{phi}\mathbin{::}\Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{phi}\mathrel{=}\mathrm{0.5}\mathbin{*}(\mathrm{1}\mathbin{+}\Varid{sqrt}\;\mathrm{5}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

We can now define a function that, for any given $a$,
yields $b$:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{golden}\mathbin{::}\Conid{Double}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{golden}\;\Varid{a}\mathrel{=}\Varid{a}\mathbin{*}\Varid{phi}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

\ensuremath{\Varid{golden}\;\mathrm{1}}, of course, is just $\Phi$, \ie\ 
\num{1.618033988749895}.
\ensuremath{\Varid{golden}\;\mathrm{2}} is twice that value, namely \num{3.23606797749979}.
Furthermore, we can state that
\ensuremath{\mathrm{2}\mathbin{/}(\Varid{golden}\;\mathrm{2}\mathbin{-}\mathrm{2})}, which is $\frac{a}{b-a}$, is
again an approximation
of $\Phi$.

That is very nice. But there is more to come.
$\Phi$, in fact, is intimately connected to the Fibonacci sequence,
as we will se in the next chapter.









\section{$\pi$}
\ignore{
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{Pi}{}\<[E]%
\\
\>[B]{}\mathbf{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Natural}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Quoz}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
}

$\pi$ is probably the most famous 
irrational number. 
It emerged in antique mathematics
in studying the circle where
it expresses the relation between
the diameter (depicted in red in the
image below) and the circumference
(depicted in black):

\begin{center}
\begin{tikzpicture}
\draw (1,1) circle (1cm);
\draw [color=red] (0.3,0.3) -- (1.7,1.7);
% \draw [color=blue] (0.3,1.7) -- (1,1);
\end{tikzpicture}
\end{center}

Since, often, the radius,
which is half the diameter, is much more
important in mathematics, it has been
proposed to use $\tau = 2\pi$ where 
$\pi$ is used today.
But $\pi$ has survived through history
and, even though slightly suboptimal
in some situations, it is still in use today.

The reason why the perimeter 
instead of the radius was used
to define the circle constant is probably
because classic approaches to approximate $\pi$
take the perimeter as basis.
They start by drawing a square with side length 1
and inscribe a circle into the square with 
perimeter 1:

\begin{center}
\begin{tikzpicture}
\draw [blue] (0,0) rectangle (2,2);
\draw (1,1) circle (1cm);
\end{tikzpicture}
\end{center}

Since the square has side length 1,
its perimeter, the sum of all its sides is
$1+1+1+1 = 4$ and, as we can see clearly
in the picture above, this perimeter
is greater than that of the circle.
4, hence, is an upper bound for the circumference
of the circle with perimeter 1.
A lower bound would then be given
by a square inscribed in the circle,
such that the distance between 
its opposing corners (red) is 1, the perimeter
of the circle:

\begin{center}
\begin{tikzpicture}
\draw [blue] (0,0) rectangle (2,2);
\draw (1,1) circle (1cm);
\draw [green] (0.3,0.3) rectangle (1.7,1.7);
\draw [color=red] (0.3,0.3) -- (1.7,1.7);
\end{tikzpicture}
\end{center}

We see two right triangles with two green sides 
on a red basis. The basis is the perimeter
of the circle, of which we know that its length is 1.
You certainly know the Pythagorean theorem,
probably the most famous or notorious theorem of all mathematics,
which states that, in a right triangle,
one with a right angle, an angle of 90°, the sum of the squares
of the sides to the left and right of that angle (the green sides)
equals the square of the hypothenuse, the red side,
which is opposite to the right angle.
This can be stated as:

\begin{equation}
a^2 = b^2 + c^2,
\end{equation}

where $a$ is the red side, whose length we know,
namely 1. We further know that the green sides
are equal. We hence have:

\begin{equation}
1^2 = 2b^2.
\end{equation}

and further derive

\begin{equation}
1 = \sqrt{2b^2},
\end{equation}

which is

\begin{equation}
1 = \sqrt{2}b.
\end{equation}

Dividing both sides by $\sqrt{2}$, 
we get 

\begin{equation}
b = \frac{1}{\sqrt{2}},
\end{equation}

the side length of the green square, which is
approximately 0.707. The perimeter of
the inner square is thus $4 \times 0.707$,
which is approximately 2.828.
Thus $\pi$ is some value between 2.828 and 4.

That result is not very satifactory, of course.
There is room for a lot of numbers between
2.828 and 4. The method was therefore extended
by choosing polygons with more than four sides
to come closer to the real value of $\pi$.
The ancient record holder for approximating $\pi$
is Archimedes who started off with a hexagon,
which is easy to construct with compass and ruler:

\begin{center}
\begin{tikzpicture}
\draw [blue] (-0.15,1) -- (0.4,2) -- (1.6,2) -- ( 2.15,1)
                       -- (1.6,0) -- (0.4,0) -- (-0.15,1);
\draw [red] (1,1) circle (1cm);
\draw [green] (0,1) -- (0.45,1.82) -- (1.55,1.82) -- (2,1) 
                    -- (1.55,0.18) -- (0.45,0.18) -- (0,1);
\end{tikzpicture}
\end{center}

Then he subsequently doubled the number of sides
of the polygon, so that he obtained polygons with
12, 24, 48 and, finally, 96 sides. With this approach
he concluded that $\frac{223}{71} < \pi < \frac{22}{7}$,
which translates to a number between 3.1408 and 3.1428
and is pretty close to the approximated value 3.14159.

In modern times, mathematicians started to search
for approximations by other means than geometry,
in particular by infinite series. One of the first series
was discovered by Indian mathematician Nilakantha Somayaji
(1444 -- 1544). It goes like

\begin{equation}
  \pi = 3 + \frac{4}{2\times 3 \times 4} -
            \frac{4}{4\times 5 \times 6} +
            \frac{4}{6\times 7 \times 8} -
            \dots
\end{equation}

We can implement this in Haskell as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{24}{@{}>{\hspre}c<{\hspost}@{}}%
\column{24E}{@{}l@{}}%
\column{25}{@{}>{\hspre}c<{\hspost}@{}}%
\column{25E}{@{}l@{}}%
\column{27}{@{}>{\hspre}l<{\hspost}@{}}%
\column{28}{@{}>{\hspre}l<{\hspost}@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{49}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{nilak}\mathbin{::}\Conid{Int}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{nilak}\;\Varid{i}{}\<[12]%
\>[12]{}\mid \Varid{even}\;\Varid{i}{}\<[25]%
\>[25]{}\mathrel{=}{}\<[25E]%
\>[28]{}\Varid{nilak}\;(\Varid{i}\mathbin{+}\mathrm{1}){}\<[E]%
\\
\>[12]{}\mid \Varid{otherwise}{}\<[25]%
\>[25]{}\mathrel{=}{}\<[25E]%
\>[28]{}\Varid{go}\;\Varid{i}\;{}\<[34]%
\>[34]{}\mathrm{2}\;\mathrm{3}\;\mathrm{4}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{go}\;\mathrm{0}\;\anonymous \;\anonymous \;\anonymous {}\<[24]%
\>[24]{}\mathrel{=}{}\<[24E]%
\>[27]{}\mathrm{3}{}\<[E]%
\\
\>[12]{}\Varid{go}\;\Varid{n}\;\Varid{a}\;\Varid{b}\;\Varid{c}{}\<[24]%
\>[24]{}\mathrel{=}{}\<[24E]%
\>[27]{}\mathbf{let}\;\Varid{k}{}\<[34]%
\>[34]{}\mid \Varid{even}\;\Varid{n}{}\<[46]%
\>[46]{}\mathrel{=}\mathbin{-}\mathrm{4}{}\<[E]%
\\
\>[34]{}\mid \Varid{otherwise}\mathrel{=}{}\<[49]%
\>[49]{}\mathrm{4}{}\<[E]%
\\
\>[27]{}\mathbf{in}\;(\Varid{k}\mathbin{/}(\Varid{a}\mathbin{*}\Varid{b}\mathbin{*}\Varid{c}))\mathbin{+}\Varid{go}\;(\Varid{n}\mathbin{-}\mathrm{1})\;\Varid{c}\;(\Varid{c}\mathbin{+}\mathrm{1})\;(\Varid{c}\mathbin{+}\mathrm{2}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Here we use a negative term, whenever $n$,
the counter for the step we are performing,
is even. Since, with this approach, an even number
of steps would produce a bad approximation, 
we perform, for $i$ even, $i+1$
and hence an odd number
of steps.
This way, the series converges to 3.14159
after about 35 steps, \ie\ \ensuremath{\Varid{nilak}\;\mathrm{35}} is
some number that starts with 3.14159.

An even faster convergence is obtained by
the beautiful series discovered by French mathematician
François Viète (1540 -- 1603) in 1593:

\begin{equation}
\frac{2}{\pi} = \frac{\sqrt{2}}{2} \times
                \frac{\sqrt{2+\sqrt{2}}}{2} \times
                \frac{\sqrt{2+\sqrt{2+\sqrt{2}}}}{2} \times
                \dots
\end{equation}

In Haskell this gives rise to a 
very nice recursive function:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{vietep}\mathbin{::}\Conid{Int}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{vietep}\;\Varid{i}\mathrel{=}\mathrm{2}\mathbin{/}(\Varid{go}\;\mathrm{0}\;(\Varid{sqrt}\;\mathrm{2})){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{go}\;\Varid{n}\;\Varid{t}{}\<[19]%
\>[19]{}\mid \Varid{n}\equiv \Varid{i}{}\<[32]%
\>[32]{}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[19]{}\mid \Varid{otherwise}{}\<[32]%
\>[32]{}\mathrel{=}(\Varid{t}\mathbin{/}\mathrm{2})\mathbin{*}\Varid{go}\;(\Varid{n}\mathbin{+}\mathrm{1})\;(\Varid{sqrt}\;(\mathrm{2}\mathbin{+}\Varid{t})){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

The approximation 3.14159 is reached with \ensuremath{\Varid{vietep}\;\mathrm{10}}.

There are many other series, 
some focusing on early convergence,
others on beauty.
An exceptionally beautiful series is
that of German polymath Gottfried Wilhelm Leibniz
(1646 -- 1716), who we will get to know more closely
later on:

\begin{equation}
\frac{\pi}{4} = \frac{1}{1} -
                \frac{1}{3} + 
                \frac{1}{5} - 
                \frac{1}{7} + 
                \frac{1}{9} -
                \dots
\end{equation}

In Haskell this is, for instance:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{19}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{35}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{54}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{leipi}\mathbin{::}\Conid{Int}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{leipi}\;\Varid{i}\mathrel{=}\mathrm{4}\mathbin{*}\Varid{go}\;\mathrm{0}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{go}\;\Varid{n}\;\Varid{d}{}\<[19]%
\>[19]{}\mid \Varid{n}\equiv \Varid{i}{}\<[32]%
\>[32]{}\mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[19]{}\mid \Varid{otherwise}{}\<[32]%
\>[32]{}\mathrel{=}{}\<[35]%
\>[35]{}\mathbf{let}\;\Varid{x}{}\<[42]%
\>[42]{}\mid \Varid{even}\;\Varid{n}{}\<[54]%
\>[54]{}\mathrel{=}\mathrm{1}{}\<[E]%
\\
\>[42]{}\mid \Varid{otherwise}\mathrel{=}\mathbin{-}\mathrm{1}{}\<[E]%
\\
\>[35]{}\mathbf{in}\;\Varid{x}\mathbin{/}\Varid{d}\mathbin{+}\Varid{go}\;(\Varid{n}\mathbin{+}\mathrm{1})\;(\Varid{d}\mathbin{+}\mathrm{2}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

This series converges really slowly.
We reach 3.14159 only after about \num{400000} steps.

$\pi$ appears quite often in mathematics,
particularly in geometry. But there are also some
unexpected entries of this number.
The inevitable Leonhard Euler solved a function,
which today is called \term{Riemann zeta function},
for the special case $s=2$:

\begin{equation}
  \zeta(s) = \frac{1}{1^s} + 
             \frac{1}{2^s} + 
             \frac{1}{3^s} + 
             \dots = \sum_{n=1}^{\infty}{\frac{1}{n^s}}.
\end{equation}

Euler showed that, for the special case $s=2$,
$\zeta(s)$ converges to $\frac{\pi^2}{6}$; in fact, for any $n$,
$n$ a multiple of 2, $\zeta(n)$
converges to some fraction of a power of $\pi$,
\eg\ $\zeta(4)$ approaches $\frac{\pi^4}{90}$,
$\zeta(6)$ approaches $\frac{\pi^6}{945}$ and so on.

This is surprising, because the zeta function
is not related to circles, but to number theory.
It appears for example, when calculating the
probability of two numbers being coprime to each other.
Two numbers are coprime if they do not share
prime factors. The probability of a number
being divisible by a given prime $p$ is $\frac{1}{p}$,
since every $p^{th}$ number is divisible by $p$.
For two independently chosen numbers, the
probability that both are divisible by prime $p$
is therefore $\frac{1}{p} \times \frac{1}{p} = \frac{1}{p^2}$.
The reverse probability that both are not divisible
by that prime, hence, is $1-\frac{1}{p^2}$.
The probablitiy that there is no prime at all
that divides both is then

\begin{equation}
  \prod_p^{\infty}{1-\frac{1}{p^2}}.
\end{equation}

To cut a long story short,
this equation can be transformed into
the equation

\begin{equation}
  \frac{1}{1+\frac{1}{2^2} + \frac{1}{3^2} + \dots} = 
  \frac{1}{\zeta(2)} = \frac{1}{\frac{\pi^2}{6}} =
  \frac{6}{\pi^2} = 0.607 \approx 61\%
\end{equation}

and with this $\pi$ appears as a constant in
number theory expressing the probability
of two randomly chosen numbers being coprime to each other.
\section{$e$}
\ignore{
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{E}{}\<[E]%
\\
\>[B]{}\mathbf{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Natural}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Quoz}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
}

The Bernoullis were a family of Huguenots from Antwerp
in the Spanish Netherlands from where they fled the repression
by the Catholic Spanish authorities, first to Frankfurt am Main,
later to Basel in Switzerland. Among the Bernoullis,
there is a remarkable number of famous mathematicians
who worked in calculus,
probability theory, number theory and many areas 
of applied mathematics. One of the Basel Bernoullis was
Johann Bernoulli (1667 -- 1748) who worked mainly
in calculus and tutored famous mathematicians like 
Guillaume L'Hôpital, but whose greatest contribution
to the history of math was perhaps to recognise 
the enormous talent of another of his pupils 
whose name was Leonhard Euler. 

His brother Jacob Bernoulli (1655 -- 1705),
who worked, as his brother, in calculus, but
most prominently in probability theory, 
is much better known today, partly perhaps
because many of Johann's achievements 
were published under the name of L'Hôpital.
Unfortunately, early modern mathematics 
and science in general was
plagued with disputes over priorities in the
authorship of contributions, a calamity
that authors and authorities later tried to
solve by introducing the \term{droite d'auteur},
better known in the English speaking world as
\term{copyright}.

Among the many problems Jacob studied was
the calculation of interests. He started off
with a very simple problem. Suppose we have
a certain amount of money and a certain interest
credited after a given amount of time. To keep it
simple, let the amount equal 1 (of any currency
of your liking -- currencies in Jacob's lifetime
were extremely complicated, so we better ignore
that detail). After one year $100\%$ interest is paid.
After that year, we hence have $1+\frac{1*100}{100} = 2$ 
in our account. That is trivial.
But what, if the interest is paid in shorter periods
during the year?
For instance, if the interest is paid twice a year,
then the interest for that period would be $50\%$.
After six months we would have $1+\frac{1*50}{100} = 1.5$
in our account. After one year, the account would then be
$1.5 + \frac{1.5*50}{100} = 1.5 + \frac{75}{100} = 1.5 + 0.75 = 2.25$.

Another way to see this is that the initial value 
is multiplied by 1.5 (the initial value plus the interest) twice:
$1 \times 1.5 \times 1.5 = 1 \times 1.5^2 = 2.25$.
When we reduce the period even further, say, to three months,
then we had $1.25^4 \approx 2.4414$. On a monthly base,
we would get $\left(1+\frac{1}{12}\right)^{12} \approx 2.613$.
On a daily basis, we would have 
$\left(1+\frac{1}{365}\right)^{365} \approx 2.7145$.
With hourly interests and the assumption
that one year has $24 \times 365 = 8760$ hours, 
we would get $\left(1+\frac{1}{8760}\right)^{8760} \approx 2.71812$.
With interest paid per minute we would get
$\left(1+\frac{1}{525600}\right)^{525600} \approx 2.71827$ and
on interest paid per second, we would get
$\left(1+\frac{1}{3156000}\right)^{3156000} \approx 2.71828$.
In general, for interest on period $n$, we get:

\[
\left(1+\frac{1}{n}\right)^n.
\] 

You may have noticed in the examples above
that this formula converges with greater and greater $n$s.
For $n$ approaching $\infty$, it converges
to $2.71828$, a number that is so beautiful that we should
look at more than just the first 5 digits:

\begin{center}
2.7 1828 1828 4590 4523$\dots$
\end{center}

This is $e$.
It is called Euler's number or, 
for the first written appearance 
of concepts related to it in 1618,
Napier's number.
It is a pity that its first mentioning
was not in the year 1828.
But who knows -- perhaps in some rare
Maya calendar the year 1618 
actually is the year 1828.

An alternative way to approach $e$
that converges much faster than the closed form above
is the following:

\[
1+\frac{1}{2}+\frac{1}{6}+\frac{1}{24}+\frac{1}{120}+\dots
\]

or, in other words:

\begin{equation}
e = \sum_{n=1}^{\infty}{\frac{1}{n!}}.
\end{equation}

We can implement this equation in Haskell as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e\char95 }\mathbin{::}\Conid{Integer}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{e\char95 }\;\Varid{p}\mathrel{=}\mathrm{1}\mathbin{+}\Varid{sum}\;[\mskip1.5mu \mathrm{1}\mathbin{/}(\Varid{dfac}\;\Varid{n})\mid \Varid{n}\leftarrow [\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\Varid{p}\mskip1.5mu]\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{dfac}\mathrel{=}\Varid{fromInteger}\mathbin{\circ}\Varid{fac}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

After some experiments with this function,
we see that
it converges already after 17 recursions
to a value that does not change with greater
arguments at \ensuremath{\Conid{Double}} precision, such that 
\ensuremath{\Varid{e\char95 }\;\mathrm{17}\equiv \Varid{e\char95 }\;\mathrm{18}\equiv \Varid{e\char95 }\;\mathrm{19}\equiv } $\dots$
We could then implement \ensuremath{\Varid{e}} as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{e}\mathbin{::}\Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{e}\mathrel{=}\Varid{e\char95 }\;\mathrm{17}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

The fact that $e$ is related to the factorial
may led to the suspicion that it also appears
directly in a formula dealing with factorials. 
There, indeed, is a formula derived by James Stirling
who we already know for the Stirling numbers.
This formula approximates the value
of $n!$ without the need to go through all
the steps of its recursive definition.
Stirling's formula is as follows:

\begin{equation}
n! \approx \sqrt{2\pi n}\left(\frac{n}{e}\right)^n.
\end{equation}

This equation is nice already because of the fact
that $e$ and $\pi$ appear together to compute
the result of an important function.
But how precise is the approximation?
To answer this question, we first implement
Stirling's formula:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{stirfac}\mathbin{::}\Conid{Integer}\to \Conid{Integer}{}\<[E]%
\\
\>[3]{}\Varid{stirfac}\;\Varid{i}\mathrel{=}\Varid{ceiling}\mathbin{\$}(\Varid{sqrt}\;(\mathrm{2}\mathbin{*}\Varid{pi}\mathbin{*}\Varid{n}))\mathbin{*}(\Varid{n}\mathbin{/}\Varid{e})\mathbin{\uparrow}\Varid{i}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{n}\mathrel{=}\Varid{fromIntegral}\;\Varid{i}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Note that we \emph{ceil} the value, instead of
rounding it just to the next integer value.

Then we define a function to compute the difference
\ensuremath{\Varid{difac}\;\Varid{n}\mathrel{=}\Varid{fac}\;\Varid{n}\mathbin{-}\Varid{stirfac}\;\Varid{n}}.
The result for the first 15 numbers is

\[
0,0,0,0,1,9,59,417,3343,30104,301174,3314113,39781324,517289459,7243645800.
\]

For the first numbers, the difference is 0. Indeed:

\begin{align*}
1! && = && stirfac(1) && = && 1\\
2! && = && stirfac(2) && = && 2\\
3! && = && stirfac(3) && = && 6\\
4! && = && stirfac(4) && = && 24
\end{align*}

Then, the functions start to disagree,
for instance $5! = 120 \neq stirfac(5) = 119$.
The difference grows rapidly and reaches more
than 3 million with $12!$. But what is the deviation
in relation to the real value?
We define the function 
\ensuremath{\mathrm{100}\mathbin{*}(\Varid{fromIntegral}\mathbin{\$}\Varid{difac}\;\Varid{n})\mathbin{/}(\Varid{fromIntegral}\mathbin{\$}\Varid{fac}\;\Varid{n})}
to obtain the difference in terms of a percentage
of the real value. We see starting from 5
(where the first difference occurs):

\[
0.8333,
1.25,
1.1706,
1.0342,
0.9212,
0.8295,
0.7545,
0.6918,
0.6388,
0.5933,
0.5539,\dots
\]

For 5, the value jumps up from 0 to $0.8333\%$,
climbs even higher to $1.25\%$ and then starts
to descrease slowly.
At 42 the deviation falls below $0.2\%$.
At 84, it falls below $0.1\%$ and keeps falling.
Even though the difference appears big
in terms of absolute numbers, the percentage
quickly shrinks and, for some problems, may
even be neglible.

A completely different way to approximate $e$
is by \term{continued fractions}.
Continued fractions are infinite fractions,
where each denominator is again a fraction.
For instance:

\begin{equation}
  e =  1 + \frac{1}{
         1 + \frac{1}{
           2 + \frac{1}{
             1 + \frac{1}{
               1 + \frac{1}{
                 4 + \frac{1}{\dots}}}}}}
\end{equation}

A more readable representation of continued fractions
is by sequences of the denominator like:

\begin{equation}
e = [2;1,2,1,1,4,1,1,6,1,1,8,1,1,\dots]
\end{equation}

where the first number is separated by a semicolon
to highlight the fact that it is not a denominator,
but an integral number added to the fraction that follows.
We can capture this very nicely in Haskell,
using just a list of integers.
However, in some cases we might have a fraction
with numerators other than 1.
An elegant way to represent this case is by
using fractions instead of integers.
We would then represent $\frac{2}{a + \dots}$
as $\frac{1}{\frac{1}{2}a + \dots}$.
Here is an implementation:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{contfrac}\mathbin{::}[\mskip1.5mu \Conid{Quoz}\mskip1.5mu]\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{contfrac}\;[\mskip1.5mu \mskip1.5mu]\mathrel{=}\mathrm{0}{}\<[E]%
\\
\>[3]{}\Varid{contfrac}\;(\Varid{i}\mathbin{:}\Varid{is})\mathrel{=}\Varid{n}\mathbin{+}\mathrm{1}\mathbin{/}(\Varid{contfrac}\;\Varid{is}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{n}\mathrel{=}\Varid{fromRational}\;\Varid{i}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

For \ensuremath{\Varid{contfrac}\;[\mskip1.5mu \mathrm{2},\mathrm{1},\mathrm{2},\mathrm{1},\mathrm{1},\mathrm{4},\mathrm{1},\mathrm{1},\mathrm{6}\mskip1.5mu]} we get 2.7183,
which is not bad, but not yet too close to $e$. 
With \ensuremath{[\mskip1.5mu \mathrm{2},\mathrm{1},\mathrm{2},\mathrm{1},\mathrm{1},\mathrm{4},\mathrm{1},\mathrm{1},\mathrm{6},\mathrm{1},\mathrm{1},\mathrm{8},\mathrm{1},\mathrm{1},\mathrm{10}\mskip1.5mu]} we get \num{2.718281828},
which is pretty close.

Examining the sequence a bit further, we see
that is has a regular structure.
We can generate it by means of the \term{Engel expansion}
named for Friedrich Engel (1861 -- 1941), 
a German mathematician who worked close with the great
Norwegian algebraist Sophus Lie (1842 -- 1899).
The Engel expansion can be implemented as follows:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{engelexp}\mathbin{::}[\mskip1.5mu \Conid{Integer}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{engelexp}\mathrel{=}\mathrm{2}\mathbin{:}\mathrm{1}\mathbin{:}\Varid{go}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{go}\;\Varid{n}\mathrel{=}(\mathrm{2}\mathbin{*}\Varid{n})\mathbin{:}\mathrm{1}\mathbin{:}\mathrm{1}\mathbin{:}\Varid{go}\;(\Varid{n}\mathbin{+}\mathrm{1}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

The following fraction, however, conoverges
must faster than the Engel expansion:
$[1,\frac{1}{2},12,5,28,9,44,13]$.
Note that we take advantage of the datatype \ensuremath{\Conid{Quoz}}
to represent a numerator that is not 1.
This sequence can be generated by means of 

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fastexp}\mathbin{::}[\mskip1.5mu \Conid{Quoz}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{fastexp}\mathrel{=}\mathrm{1}\mathbin{:}(\mathrm{1}\mathbin{\%}\mathrm{2})\mathbin{:}\Varid{go}\;\mathrm{1}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{go}\;\Varid{n}\mathrel{=}(\mathrm{16}\mathbin{*}\Varid{n}\mathbin{-}\mathrm{4})\mathbin{:}(\mathrm{4}\mathbin{*}\Varid{n}\mathbin{+}\mathrm{1})\mathbin{:}\Varid{go}\;(\Varid{n}\mathbin{+}\mathrm{1}){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

This fraction converges already after 7 steps
to the value \num{2.718281828}: 

\ensuremath{\Varid{contfrac}\;(\Varid{take}\;\mathrm{7}\;\Varid{fastexp})}. 

The area of mathematics where $e$ is really at home
is analysis and its vast areas of application, 
which we will study in the third part of this series.
The reason for the prominence of $e$ in analysis
stems from the \term{natural logarithm},
which we already introduced in the first chapter.
The natural logarithm of a number $n$, 
usually denoted $\ln(n)$,
is the exponent $x$, such that $e^x = n$.

The natural logarithm can be graphed as follows:

\begin{center}
\begin{tikzpicture}[trim axis left]
\begin{axis}[
  step=1,
  domain=0:10,
  samples=100,
  % enlarge x limits=true,
  ymin=-2,ymax=5,
  xmin=0.01,xmax=10,xstep=1,
  grid=both,
  %axis equal,
  no markers]
\addplot +[thick] {ln(x)};
\addplot [black] {0};
\end{axis}
\end{tikzpicture}
\end{center}

The curious fact that earned the natural logarithm its name
is that, at $x=1$, the curve has the slope 1.
This might sound strange for the moment.
We will investigate that later.


\section{$\gamma$}
\ignore{
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{Gamma}{}\<[E]%
\\
\>[B]{}\mathbf{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Natural}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{import}\;\Conid{Quoz}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
}

The \term{harmonic series} is defined as

\begin{equation}
\sum_{n=1}^{\infty}{\frac{1}{n}} = 1 + 
  \frac{1}{2} + 
  \frac{1}{3} + 
  \frac{1}{4} + \dots
\end{equation}

A harmonoic series with respect to a given number $k$,
called the \term{harmonic number} $H_k$, then is

\begin{equation}
\sum_{n=1}^k{\frac{1}{n}} = 1 + 
  \frac{1}{2} + \dots
  \frac{1}{k} 
\end{equation}

This is easily implemented in Haskell as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{harmonic}\mathbin{::}\Conid{Natural}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{harmonic}\;\Varid{n}\mathrel{=}\Varid{sum}\;[\mskip1.5mu \mathrm{1}\mathbin{/}\Varid{d}\mid \Varid{d}\leftarrow \Varid{map}\;\Varid{fromIntegral}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\Varid{n}\mskip1.5mu]\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Some harmonic numbers are (\ensuremath{\Varid{map}\;\Varid{harmonic}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\mathrm{10}\mskip1.5mu]}):

$1, 1.5, 1.8\overline{3}, 2.08\overline{3}, 2.28\overline{3}, 
 2.44\overline{9}, 2.5928,2.7178, 2.8289, 2.9289.$

The harmonic series is an interesting object of study
in its own right. Here, however, we are interested in 
something else. Namely, the difference of the harmonic series
and the natural logarithm:

\begin{equation}
\gamma = \lim_{n \to \infty} H_n - \ln(n).
\end{equation}

We can implement this equation as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{harmonatural}\mathbin{::}\Conid{Natural}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{harmonatural}\;\Varid{n}\mathrel{=}\Varid{harmonic}\;\Varid{n}\mathbin{-}\Varid{ln}\;\Varid{n}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;\Varid{ln}\mathrel{=}\Varid{log}\mathbin{\circ}\Varid{fromIntegral}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Applied on the first numbers with
\ensuremath{\Varid{map}\;\Varid{harmonatural}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\mathrm{10}\mskip1.5mu]}, the function
does not show interesting results:

$1.0, 0.8068,0.7347,0.697,0.6738,0.6582,0.6469,0.6384,0.6317,0.6263,\dots$

Applied to greater numbers, however, the results approach a constant value:

\ensuremath{\Varid{harmonatural}\;\mathrm{100}\mathrel{=}\mathrm{0.58220}}\\
\ensuremath{\Varid{harmonatural}\;\mathrm{1000}\mathrel{=}\mathrm{0.57771}}\\
\ensuremath{\Varid{harmonatural}\;\mathrm{10000}\mathrel{=}\mathrm{0.57726}}\\
\ensuremath{\Varid{harmonatural}\;\mathrm{100000}\mathrel{=}\mathrm{0.57722}}

With even greater numbers, the difference converges to \num{0.57721}.
This number, $\gamma$, was first mentioned by -- surprise -- 
Leonhard Euler and some years later 
by Italian mathematician Lorenzo Mascheroni (1750 -- 1800) and
is therefore called the Euler-Mascheroni constant.

This mysterious number appears in different contexts and, apparently,
quite often as a difference or average.
An ingenious investigation was carried out by Belgian mathematician
Charles Jean de la Vallée-Poussin (1866 -- 1962) who is famous
for his proof of the Prime number theorem.
Vallée-Poussin studied the quotients of a number $n$ 
and the primes up to that number. If $n$ is not prime itself,
then there are some prime numbers $p$, 
namely those of the prime factorisation of $n$,
such that $\frac{n}{p}$ is an integer. 
For others, this quotient is a rational number,
which falls short of the next natural number.
For instance, there are four prime numbers less than 10:
2, 3, 5 and 7. The quotients are

$5, 3.\overline{3}, 2, 1.\overline{428571}$.

5 and 2, the quotients of 2 and 5, respectively,
are integers and there, hence, is no difference.
The quotient $\frac{10}{3} = 3.\overline{3}$, however,
falls short of 4 by $0.\overline{6}$ and
$\frac{10}{7} = 1.\overline{428571}$ falls short of 2 by
$0.\overline{57142828}$.

Vallée-Poussin asked what the average of this difference is.
For the example 10, the average is about
$0.3\overline{095238}$. 
One might think that this average, computed for many numbers
or for very big numbers, is about $0.5$, so that the probability
for the quotient of $n$ and a random prime number 
to fall into the first or the second half of the rational numbers
between two integers is equal, \ie\ $50\%$ for both cases.
It turns out it is not.
For huge numbers, de la Vallée-Poussin's average converges
to \num{0.57721}, the Euler-Mascheroni constant.

It converges quite slow, however.
If we implement the prime quotient as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{pquoz}\mathbin{::}\Conid{Natural}\to [\mskip1.5mu \Conid{Double}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{pquoz}\;\Varid{n}\mathrel{=}[\mskip1.5mu \Varid{d}\mathbin{/}\Varid{p}\mid \Varid{p}\leftarrow \Varid{ps}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{ps}{}\<[16]%
\>[16]{}\mathrel{=}\Varid{map}\;\Varid{fromIntegral}\;(\Varid{takeWhile}\;(\mathbin{<}\Varid{n})\;\Varid{allprimes}){}\<[E]%
\\
\>[12]{}\Varid{d}{}\<[16]%
\>[16]{}\mathrel{=}\Varid{fromIntegral}\;\Varid{n}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

and its average as

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{pquozavg}\mathbin{::}\Conid{Integer}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{pquozavg}\;\Varid{n}\mathrel{=}(\Varid{sum}\;\Varid{ds})\mathbin{/}(\Varid{fromIntegral}\mathbin{\$}\Varid{length}\;\Varid{ds}){}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[12]%
\>[12]{}\Varid{qs}{}\<[16]%
\>[16]{}\mathrel{=}\Varid{pquoz}\;\Varid{n}{}\<[E]%
\\
\>[12]{}\Varid{ns}{}\<[16]%
\>[16]{}\mathrel{=}\Varid{map}\;(\Varid{fromIntegral}\mathbin{\circ}\Varid{ceiling})\;\Varid{qs}{}\<[E]%
\\
\>[12]{}\Varid{ds}{}\<[16]%
\>[16]{}\mathrel{=}[\mskip1.5mu \Varid{n}\mathbin{-}\Varid{q}\mid (\Varid{n},\Varid{q})\leftarrow \Varid{zip}\;\Varid{ns}\;\Varid{qs}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

we can experiment with some numbers like

\ensuremath{\Varid{pquozavg}\;\mathrm{10}\mathrel{=}}$0.3\overline{095238}$\\
\ensuremath{\Varid{pquozavg}\;\mathrm{100}\mathrel{=}\mathrm{0.548731}}\\
\ensuremath{\Varid{pquozavg}\;\mathrm{1000}\mathrel{=}\mathrm{0.5590468}}\\
\ensuremath{\Varid{pquozavg}\;\mathrm{10000}\mathrel{=}\mathrm{0.5666399}}\\
\ensuremath{\Varid{pquozavg}\;\mathrm{100000}\mathrel{=}\mathrm{0.5695143}}\\
$\dots$

With greater and greater numbers, this value
approaches $\gamma$. Restricting $n$ to prime numbers
produces good approximations of $\gamma$ much earlier. 
From 7 on, \ensuremath{\Varid{pquozavg}} with primes results in numbers of the form
$0.5\dots$ \ensuremath{\Varid{pquozavg}\;\mathrm{43}\mathrel{=}\mathrm{0.57416}} 
is already very close to $\gamma$.
It may be mentioned that 43 is suspiciously close to 42.

With de la Vallée-Pussin's result in mind,
it is not too surprising that $\gamma$ is related
to divisors and Euler's totient number.
A result of Gauss' immediate successor in Göttingen, 
Peter Gustav Lejeune-Dirichlet (1805 -- 1859),
is related to the average number of divisors
of the numbers $1\dots n$.
We have already defined a function to generate
the divisors of a number $n$, namely \ensuremath{\Varid{divs}}.
Now we map this function on all numbers up to $n$:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{divsupn}\mathbin{::}\Conid{Natural}\to [\mskip1.5mu [\mskip1.5mu \Conid{Natural}\mskip1.5mu]\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{divsupn}\;\Varid{n}\mathrel{=}\Varid{map}\;\Varid{divs}\;[\mskip1.5mu \mathrm{1}\mathinner{\ldotp\ldotp}\Varid{n}\mskip1.5mu]{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Applied to 10, this function yields:

\ensuremath{[\mskip1.5mu [\mskip1.5mu \mathrm{1}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{2}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{3}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{4}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{5}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{3},\mathrm{6}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{7}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{4},\mathrm{8}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{3},\mathrm{9}\mskip1.5mu],[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{5},\mathrm{10}\mskip1.5mu]\mskip1.5mu]}

For modelling Lejeune-Dirichlet's result,
we further need to count the numbers of divisors
of each number:

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{ndivs}\mathbin{::}\Conid{Integer}\to [\mskip1.5mu \Conid{Int}\mskip1.5mu]{}\<[E]%
\\
\>[3]{}\Varid{ndivs}\mathrel{=}\Varid{map}\;\Varid{length}\mathbin{\circ}\Varid{divsupn}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

Applied again to 10, \ensuremath{\Varid{ndivs}} produces:

\ensuremath{[\mskip1.5mu \mathrm{1},\mathrm{2},\mathrm{2},\mathrm{3},\mathrm{2},\mathrm{4},\mathrm{2},\mathrm{4},\mathrm{3},\mathrm{4}\mskip1.5mu]}

Now we compute the average of this list using

\begin{minipage}{\textwidth}
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{17}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{dirichlet}\mathbin{::}\Conid{Integer}\to \Conid{Double}{}\<[E]%
\\
\>[3]{}\Varid{dirichlet}\;\Varid{n}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{s}\mathbin{/}\Varid{l}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathbf{where}\;{}\<[13]%
\>[13]{}\Varid{ds}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{ndivs}\;\Varid{n}{}\<[E]%
\\
\>[13]{}\Varid{l}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{fromIntegral}\mathbin{\$}\Varid{length}\;\Varid{ds}{}\<[E]%
\\
\>[13]{}\Varid{s}{}\<[17]%
\>[17]{}\mathrel{=}\Varid{fromIntegral}\mathbin{\$}\Varid{sum}\;\Varid{ds}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
\end{minipage}

For \ensuremath{\Varid{dirichlet}\;\mathrm{10}} we see 2.7.
This does not appear too spectacular.
Greater numbers show:

\ensuremath{\Varid{dirichlet}\;\mathrm{100}\mathrel{=}\mathrm{4.759}}\\
\ensuremath{\Varid{dirichlet}\;\mathrm{250}\mathrel{=}\mathrm{5.684}}\\
\ensuremath{\Varid{dirichlet}\;\mathrm{500}\mathrel{=}\mathrm{6.38}}\\
\ensuremath{\Varid{dirichelt}\;\mathrm{1000}\mathrel{=}\mathrm{7.069}}

As we can see, the number is slowly increasing
resembling a log function or, more specifically,
the natural log. When we compare the natural log,
we indeed see that the results are close:

$\ln 100  = 4.605$\\
$\ln 250  = 5.521$\\
$\ln 500  = 6.214$\\
$\ln 1000  = 6.907$

For greater and greater numbers,
the difference of 
the \ensuremath{\Varid{dirichlet}} function and 
the natural logarithm approaches

\begin{equation}
0.154435 \approx 2\gamma - 1.
\end{equation}

For the five examples above, the difference
is still significantly away from that number:

$\Delta 100 = 0.2148$\\
$\Delta 250 = 0.1625$\\
$\Delta 500 = 0.1635$\\
$\Delta 1000= 0.1612$,

but already $\Delta 2000 = 0.158$ comes close and
$\Delta 4000 = 0.1572$ 
approaches the value even further.

An important constant derived from $\gamma$ is
$e^{\gamma}$, which is a limit often seen in 
number theory. One instance is the lower bound
of the totient function. There is a clear upper bound,
namely $n-1$. Indeed, $\varphi(n)$ can never 
yield a value greater $n-1$ and this upper bound
is reached exclusively by prime numbers.
There is no such linear lower bound. 
That is, $\varphi(n)$ can assume values that are much smaller
than the value seen for $n-1$ or other numbers less than $n$.
But there is a lower bound that slowly grows with $n$.
This lower bound is often given as $\frac{n}{\ln\ln n}$.
This lower bound, however, is too big.
There are some values that are still below that border.
$\varphi(40)$, for instance, is 16.
$\frac{40}{\ln \ln 40}$, however, is around 30.
A better, even still not perfect approximation, is

\[
\frac{n}{e^{\gamma}\ln \ln n}.
\]

For the $n=40$ again,
$\frac{40}{e^{\gamma}\ln \ln 40}$ is around 17 and, hence,
very close to the real value.

We see that $\gamma$ is really a quite mysterious number
that appears in different contexts, sometimes in quite
a subtle manner.
The greatest mystery, however, is that it is not so clear
that this number belongs here in the first place.
Indeed, it has not yet been shown that $\gamma$ is irrational.
In the approximations, we have studied in this section,
we actually have not seen 
the typical techniques to create irrational numbers 
like roots, continuous fractions and infinite series.
If $\gamma$ is indeed rational, then it must be the fraction
of two really large numbers. In 2003, it has been shown
that the denominator of such a fraction must be greater
than $10^{242080}$. 
A number big enough, for my taste, to speak of \speech{irrational}.
\section{Representation of Real Numbers} % natural numbers and fractions
%inlcude Realrep.lhs
\section{$\mathbb{R}$}
%inlcude Real.lhs
\section{Real Factorials}
\section{Real Binomial Coefficients}
\section{The Continuum}
\section{Review of the Number Zoo}


\end{document}
